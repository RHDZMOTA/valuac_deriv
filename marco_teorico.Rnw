%% No modificar el comando \Sexpr
\Sexpr{set_parent('code_master.Rnw')}

\chapter{Marco teórico}
Markov Chain Monte Carlo:

Supongamos que es necesario generar $x\sim\pi(x)$. La idea principal de MCMC es el de construir una cadena de Markov para una $x(i)$ en cada posici\'on, que inicie desde que $i=0$ hasta infinito que cumpla con lo siguiente: \begin{equation} \label{eq:1} \lim_{i \to \infty} P(x(i)=x) = \pi (x) \end{equation}. Una cadena de Markov est\'a pre-definida por un estado inicial $P(X_0 = x_0 = g(x_0))$. y el Kernel de transici\'on $P(y|x) = P(X_i+1=y|X_i=x)$. Si la cadena es erg\'odica, entonces la distribuci\'on es \'unica. $\Pi(x):\lim_{i \to \infty} f(x_i)$ Por lo tanto \begin{equation} \label{eq:2} \pi(y)= \sum \pi(x) p(y|x) \forall y \in \cap \end{equation}. Una vez definida esta ecuaci\'on, ser\'a necesario implementarla para cada x, obteniendo el siguiente sistema de ecuaciones:\begin{equation} \label{eq:3} 
\pi(x_2)= \pi (x_1) p(x_2|x_1) + \pi (x_1) p(x_2|x_1) + ...\pi(x_n) p(x_2|x_n)
\end{equation}.
\begin{equation} \label{eq:4} 
\pi(x_n)= \pi (x_1) p(x_n|x_1) + \pi (x_2) p(x_n|x_2) + ...\pi(x_n) p(x_n|x_n)
\end{equation}.

Existe un n\'umero infinito de Kernel's de transici\'on  $P(y|x)$ tales que satisfagan el sistema de ecuaciones anterior.Para este se utilizó el algoritmo de \emph {Metropolis-Hastings} para construir el Kernel de transici\'on. En este algoritmo se propone una distribución de transición arbitraria denominada $Q$. Por lo tanto, ahora existe una probabilidad de que $Q(y|x)=p(y|x)$.

En notación matemática se obtiene:
\begin{equation} \label{eq:5} 
P(y|x) = Q(y|x) \alpha(y|x), y \neq x, \alpha(y|x), \varepsilon [0;1] 
\end{equation}.

La condici\'on o propiedad para una cadena de Markov homogénea, es la siguiente:
\begin{equation} \label{eq:6} 
\pi(x) Q(y|x) \alpha(y|x) = \pi(y) Q(x|y) \alpha(x|y), \forall x\neq y
\end{equation}.

Utilizando las dos ecuaciones anteriores (\ref{eq:5}, \ref{eq:6}) se obtiene la solución:
\begin{equation} \label{eq:7} 
\alpha(y|x) = \gamma(x,y) \pi (y) Q(x|y)
\end{equation}.

Ajustando la función $\gamma$ para tener un mayor radio de aceptación, se tiene que:
\begin{equation} \label{eq:8} 
\alpha(y|x) = min\left(1, \frac{\pi(y)Q(x|x)}{\pi(x)Q(y|x)}\right)
\end{equation}.

\section{Estimaci\'on de densidad de probabilidad no param\'etrica}
\begin{equation} \label{eq:9} 
f(x)= \frac{1}{nh} \sum_{i = 1}^n K (\frac{x-X_i}{h})
\end{equation}.
Donde K es la funci\'on de Kernel, $h$ el ancho de banda y $n$ es el tamaño de muestra.

Existen diferentes funciones que pueden ser utilizadas para nuestro objetivo, en este caso, se utilizó el Kernel de tipo Gauss para  suavizar el histograma de frecuencias. La metodología general consta en evaluar la función kernel ($K$) para cada uno de los datos y la suma de todas estas distribuciones es la distribución resultante.

El kernel gaussiano viene dado por: 
\begin{equation} \label{eq:10}
K(x) = \frac {1}{\sqrt{2\pi} }exp^\frac{-x^2}{2}
\end{equation}.
La distribución resultante se identificará como la función objetivo.

\section{Función propuesta ($Q$)}

Se propone $q(x)$ como el histograma de frecuencia, tomado como una función por partes. Se utiliza el método de la inversa para generar $n$ números aleatorios cuya distribución se asemeja a $q(x)$. 


 y a continuaci\'on se calcula $f(x)$. y se determina $\alpha(y|x) = min\left(1, \frac{f(y)q(x)}{f(x)q(y)}\right)$ con esto, la probabilidad de transici\'on ser\'a $p(y|x) = Q(y)\alpha(y|x)$. 

Por lo tanto, la funci\'on de densidad, para cada punto ser\'a la siguiente:
$f_n(x) = \frac{1}{nh} \sum K(\frac{x-x_i}{n}); -\infty < x < \infty$
donde $K()$ es la funci\'on suavificante de Kernel y h es el ancho de banda. 

